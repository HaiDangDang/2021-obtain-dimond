Using cuda device
Wrapping the env in a VecTransposeImage.
Logging to runs/v1/PPO_9
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 951      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    fps             | 22       |
|    iterations      | 1        |
|    time_elapsed    | 464      |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.07e+03    |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 32          |
|    iterations           | 2           |
|    time_elapsed         | 629         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.028625125 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.787      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0756     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0355     |
|    value_loss           | 0.00142     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.29e+03   |
|    ep_rew_mean          | 0          |
| time/                   |            |
|    fps                  | 39         |
|    iterations           | 3          |
|    time_elapsed         | 786        |
|    total_timesteps      | 30720      |
| train/                  |            |
|    approx_kl            | 0.04492546 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.91      |
|    explained_variance   | -0.165     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0934    |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0591    |
|    value_loss           | 0.000563   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.85e+03    |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 4           |
|    time_elapsed         | 1020        |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.054863226 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.112       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.12       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0708     |
|    value_loss           | 0.000184    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.82e+03    |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 44          |
|    iterations           | 5           |
|    time_elapsed         | 1139        |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.075211406 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | -0.0274     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.125      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0769     |
|    value_loss           | 6.25e-05    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.17e+03    |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 6           |
|    time_elapsed         | 1284        |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.088539466 |
|    clip_fraction        | 0.478       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.081       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0655     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0659     |
|    value_loss           | 0.000706    |
-----------------------------------------
Failed to take a step (error timed out). Terminating episode and sending random observation, be aware. To account for this failure case in your code check to see if `'error' in info` where info is the info dictionary returned by the step function.
Traceback (most recent call last):
  File "/home/dang/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-2-42553eda6085>", line 179, in <module>
    model.learn(total_timesteps=2000000)  # 2m steps is about 8h at 70 FPS
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py", line 308, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 234, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 175, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
    return self.step_wait()
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 83, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 49, in step_wait
    obs = self.envs[env_idx].reset()
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/gym/wrappers/record_episode_statistics.py", line 17, in reset
    observation = super(RecordEpisodeStatistics, self).reset(**kwargs)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/gym/core.py", line 237, in reset
    return self.env.reset(**kwargs)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/gym/core.py", line 289, in reset
    return self.env.reset(**kwargs)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/gym/core.py", line 264, in reset
    observation = self.env.reset(**kwargs)
  File "/home/dang/anaconda3/envs/mine/lib/python3.7/site-packages/gym/wrappers/time_limit.py", line 25, in reset
    return self.env.reset(**kwargs)
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/_singleagent.py", line 22, in reset
    multi_obs = super().reset()
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/_multiagent.py", line 455, in reset
    self._setup_instances()
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/_multiagent.py", line 569, in _setup_instances
    self._TO_MOVE_quit_current_episode(instance)
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/_multiagent.py", line 757, in _TO_MOVE_quit_current_episode
    reply = instance.client_socket_recv_message()
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/malmo.py", line 458, in client_socket_recv_message
    return comms.recv_message(self.client_socket)
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/comms.py", line 63, in recv_message
    lengthbuf = recvall(sock, 4)
  File "/home/dang/.local/lib/python3.7/site-packages/minerl/env/comms.py", line 73, in recvall
    newbuf = sock.recv(count)
